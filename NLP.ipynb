{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1H_YZ6NGIKZQImKlTnaRyoYYwlSIq3zO-",
      "authorship_tag": "ABX9TyM7NUK02x23oTp4M1aBn9Bs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiswaryajoseph2004-bot/Natural-Language-Processing-NLP-/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove stop words"
      ],
      "metadata": {
        "id": "YK4CnIJcJvJT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANmkXHJIIePU",
        "outputId": "f8ef38b5-81c9-4056-942f-5d305e22df49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample', 'sentence', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "text='This is a sample sentence.'\n",
        "words=word_tokenize(text)\n",
        "filtered=[w for w in words if w.lower() not in stopwords.words('english')]\n",
        "print(filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "osJgY4YYJ0nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize('This is a sentence.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR7P8jWSJjKO",
        "outputId": "fcc78db9-f43f-4d03-a469-ffb0d2c4d1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sentence', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "4ryIyNriKKQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "print(stemmer.stem('running'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibzXQ0zsKJGl",
        "outputId": "34a14d8e-d02c-4220-82fc-61c4490dc797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "PMgu_-jDKk5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "print(lemmatizer.lemmatize('running',pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rohCph65KjuN",
        "outputId": "4c7a781e-c0ec-444b-9100-18c7a8477ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "stemmer=PorterStemmer()\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "word1='running'\n",
        "word2='better'\n",
        "word3='studies'\n",
        "\n",
        "print('Stemming:')\n",
        "print(stemmer.stem(word1))\n",
        "print(stemmer.stem(word2))\n",
        "print(stemmer.stem(word3))\n",
        "\n",
        "print('\\nLemmatization:')\n",
        "print(lemmatizer.lemmatize(word1, pos='v'))\n",
        "print(lemmatizer.lemmatize(word2, pos='a'))\n",
        "print(lemmatizer.lemmatize(word3, pos='n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXMQ1f23K7xD",
        "outputId": "24626603-a486-458b-eaa2-f5dcfda7befd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming:\n",
            "run\n",
            "better\n",
            "studi\n",
            "\n",
            "Lemmatization:\n",
            "run\n",
            "good\n",
            "study\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pos(part of speech) Tagging"
      ],
      "metadata": {
        "id": "Fpynxgr5Osnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens=word_tokenize(\"This is a sample sentence\")\n",
        "\n",
        "print(nltk.pos_tag(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boBHi4rrMipz",
        "outputId": "f402390d-ec7d-4211-df8d-d39828c915a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sample', 'JJ'), ('sentence', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER(Name entity recogintion)"
      ],
      "metadata": {
        "id": "DsQJJvAeQuNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg_O1MZ9QsvJ",
        "outputId": "bd21da23-b259-4602-f802-2295b345d725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Barack Obama', 'PERSON'), ('Hawaii', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "print([(ent.text,ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLSue-IxRhwL",
        "outputId": "dde8d537-3fa6-4ad0-fd74-2a160289c90e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chunking"
      ],
      "metadata": {
        "id": "B53MLinCSo24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "text='The quick brown fox jumps over the lazy dog'\n",
        "tokens = nltk.word_tokenize(text)\n",
        "tags=nltk.pos_tag(tokens)\n",
        "chunk_grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp=nltk.RegexpParser(chunk_grammar)\n",
        "tree = cp.parse(tags)\n",
        "tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTSSc5kbSnKZ",
        "outputId": "2c7ac52f-6d59-4a4a-e143-c57294cf9c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     S                                 \n",
            "     ________________________________|______________________            \n",
            "    |        |              NP               NP             NP         \n",
            "    |        |       _______|________        |       _______|______     \n",
            "jumps/VBZ over/IN The/DT quick/JJ brown/NN fox/NN the/DT lazy/JJ dog/NN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# word Embedding or Vectorization"
      ],
      "metadata": {
        "id": "KhVCaFBgTuHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "x=cv.fit_transform([\"This is a sample\",\"This is another example\"])\n",
        "print(x.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LDXyl6oTnlr",
        "outputId": "d6d467ef-9743-44cb-f272-fd630595d7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 1 1]\n",
            " [1 1 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXK9u7lqUxuo",
        "outputId": "5308bb95-865d-4ff0-cbac-c88875919444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['another' 'example' 'is' 'sample' 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "8spXHoBhVBUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf = TfidfVectorizer()\n",
        "x = tf.fit_transform([\"This is a sample\", \"This is another example\"])\n",
        "print(tf.get_feature_names_out())\n",
        "print(x.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgP9nDQNU_nQ",
        "outputId": "b6301824-0f2d-4964-ac45-2bb0d69698d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['another' 'example' 'is' 'sample' 'this']\n",
            "[[0.         0.         0.50154891 0.70490949 0.50154891]\n",
            " [0.57615236 0.57615236 0.40993715 0.         0.40993715]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# countvectorizer to extract n_grams"
      ],
      "metadata": {
        "id": "vQSa_MahWnWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text = [\"I love NLP\"]\n",
        "cv = CountVectorizer(ngram_range=(1,3))\n",
        "X = cv.fit_transform(text)\n",
        "print(cv.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqMESBrYWKLo",
        "outputId": "54f8c62c-6e78-4d66-9049-0203d686f5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['love' 'love nlp' 'nlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(1, 1) (default) Only single words (unigrams)\n",
        "\n",
        "(1, 2) Unigrams and bigrams\n",
        "\n",
        "(2, 2) Only bigrams\n",
        "\n",
        "(1, 3) Unigrams, bigrams, and trigrams**"
      ],
      "metadata": {
        "id": "fZHtQWiXXK4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sentiment analysis"
      ],
      "metadata": {
        "id": "RM_oJHgwXhV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " <b>Polarity: 0.5 </b> <br> <hr>\n",
        "Range: from -1.0 (most negative) to +1.0 (most positive) <br>\n",
        "Meaning: A value of 0.5 indicates a moderately positive sentiment. <br>\n",
        "Negative: < 0 <br>\n",
        "Neutral: 0 <br>\n",
        "Positive: > 0 <br>\n",
        " <b>Subjectivity: 0.6 </b> <br> <hr>\n",
        "Range: from 0.0 (objective) to 1.0 (subjective)<br>\n",
        "Meaning: A value of 0.6 suggests the text is fairly subjective, meaning it's based more on personal opinion or feelings than on factual information.\n",
        "\n"
      ],
      "metadata": {
        "id": "OUIXvAZsPsDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "print(TextBlob(\"I love this product\").sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBpIgrpjW5Ra",
        "outputId": "0a14b409-6ee2-473b-c400-bd26cc7a345e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.5, subjectivity=0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Term             | Simple meaning                     |\n",
        "| ---------------- | ---------------------------------- |\n",
        "| **Polarity**     | How negative or positive it is     |\n",
        "| **Subjectivity** | How much of it is opinion vs. fact |\n"
      ],
      "metadata": {
        "id": "xdI4VFK8aEIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Term             | Range                      | Meaning                                      |\n",
        "| ---------------- | -------------------------- | -------------------------------------------- |\n",
        "| **Polarity**     | `-1.0` to `+1.0`           | How **negative** or **positive** the text is |\n",
        "|                  | `-1.0` → Very negative     | Example: *“I hate this movie.”*              |\n",
        "|                  | `0.0` → Neutral            | Example: *“It is a movie.”*                  |\n",
        "|                  | `+1.0` → Very positive     | Example: *“I love this movie!”*              |\n",
        "|                  |                            |                                              |\n",
        "| **Subjectivity** | `0.0` to `1.0`             | How much is **opinion** vs. **fact**         |\n",
        "|                  | `0.0` → Completely factual | Example: *“The sun rises in the east.”*      |\n",
        "|                  | `1.0` → Fully opinionated  | Example: *“I think this is the best ever!”*  |\n"
      ],
      "metadata": {
        "id": "l60NQaOFZ-ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text classification with pipeline"
      ],
      "metadata": {
        "id": "DFEgGGbwYace"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#  Example text data (spam detection style)\n",
        "texts=[\n",
        "    \"Buy now\",\n",
        "    \"Limited offer\",\n",
        "    \"call me later\",\n",
        "    \"meeting at noon\",\n",
        "    \"free coupons\",\n",
        "    \"Let's have lunch\",\n",
        "    \"win a prize now\",\n",
        "    \"project discussion tomorrow\"\n",
        "]\n",
        "\n",
        "labels=[\n",
        "    \"spam\",\n",
        "    \"spam\",\n",
        "    \"ham\",\n",
        "    \"ham\",\n",
        "    \"spam\",\n",
        "    \"ham\",\n",
        "    \"spam\",\n",
        "    \"ham\"\n",
        "]\n",
        "#  Split into training and testing data\n",
        "x_train,x_test,y_train,y_test = train_test_split(\n",
        "    texts,labels,test_size=0.25,random_state=42\n",
        ")\n",
        "#  Create the pipeline\n",
        "pipe=Pipeline([\n",
        "    ('vectorizer',CountVectorizer()),\n",
        "    ('classifier',MultinomialNB())\n",
        "])\n",
        "\n",
        "#  Train the model\n",
        "pipe.fit(x_train,y_train)\n",
        "\n",
        "#  Make predictions\n",
        "preds = pipe.predict(x_test)\n",
        "\n",
        "#  Evaluate the model\n",
        "print(\"Test predictions:\", preds)\n",
        "print(\"Actual labels:   \", y_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "#  Try a new example\n",
        "new_text = [\"Congratulations, you won a free ticket!\"]\n",
        "new_pred = pipe.predict(new_text)\n",
        "print(\"\\nNew text:\", new_text[0])\n",
        "print(\"Predicted label:\", new_pred[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwLKmmekYSLP",
        "outputId": "75906759-e263-44b9-bd3c-18701474b2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions: ['ham' 'ham']\n",
            "Actual labels:    ['spam', 'ham']\n",
            "Accuracy: 0.5\n",
            "\n",
            "New text: Congratulations, you won a free ticket!\n",
            "Predicted label: spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "nAtDijBcOlPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dataset/email.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QqdgEEyGSQ0y",
        "outputId": "265565b0-f26b-4374-fbf0-33260d58145d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Category                                            Message\n",
              "0                ham  Go until jurong point, crazy.. Available only ...\n",
              "1                ham                      Ok lar... Joking wif u oni...\n",
              "2               spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3                ham  U dun say so early hor... U c already then say...\n",
              "4                ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...              ...                                                ...\n",
              "5568             ham               Will ü b going to esplanade fr home?\n",
              "5569             ham  Pity, * was in mood for that. So...any other s...\n",
              "5570             ham  The guy did some bitching but I acted like i'd...\n",
              "5571             ham                         Rofl. Its true to its name\n",
              "5572  {\"mode\":\"full\"                                    isActive:false}\n",
              "\n",
              "[5573 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d07f204-5faa-44d5-a559-06a2ed8e488e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5572</th>\n",
              "      <td>{\"mode\":\"full\"</td>\n",
              "      <td>isActive:false}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5573 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d07f204-5faa-44d5-a559-06a2ed8e488e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d07f204-5faa-44d5-a559-06a2ed8e488e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d07f204-5faa-44d5-a559-06a2ed8e488e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1e5e10e3-5cf9-4a3c-8a9b-2cf032c3ed83\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1e5e10e3-5cf9-4a3c-8a9b-2cf032c3ed83 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5573,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ham\",\n          \"spam\",\n          \"{\\\"mode\\\":\\\"full\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5158,\n        \"samples\": [\n          \"&lt;#&gt;  am I think? Should say on syllabus\",\n          \"Yar lor... How u noe? U used dat route too?\",\n          \"En chikku nange bakra msg kalstiya..then had tea/coffee?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "CgJDkXjRSc5W",
        "outputId": "3f09694f-500a-4fc6-f784-6ff925822ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Category    0\n",
              "Message     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Category</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Message</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x=df[\"Message\"]\n",
        "y=df[\"Category\"]\n",
        "x_train,x_test,y_train,y_test = train_test_split(\n",
        "   x,y,test_size=0.25,random_state=42\n",
        ")\n",
        "\n",
        "pipe=Pipeline([\n",
        "    ('vectorizer',CountVectorizer()),\n",
        "    ('classifier',MultinomialNB())\n",
        "])\n",
        "\n",
        "\n",
        "pipe.fit(x_train,y_train)\n",
        "\n",
        "preds = pipe.predict(x_test)\n",
        "\n",
        "print(\"Test predictions:\", preds)\n",
        "print(\"Actual labels:   \", y_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "#  Try a new example\n",
        "new_text = [\"Congratulations, you won a free ticket!\"]\n",
        "new_pred = pipe.predict(new_text)\n",
        "print(\"\\nNew text:\", new_text[0])\n",
        "print(\"Predicted label:\", new_pred[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT3buxf_TPMG",
        "outputId": "38ceb172-8e32-4a5f-f6d0-b702a56396c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions: ['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n",
            "Actual labels:    3690     ham\n",
            "3527     ham\n",
            "724      ham\n",
            "3370     ham\n",
            "468      ham\n",
            "        ... \n",
            "19      spam\n",
            "4757     ham\n",
            "668      ham\n",
            "218      ham\n",
            "5395     ham\n",
            "Name: Category, Length: 1394, dtype: object\n",
            "Accuracy: 0.9849354375896701\n",
            "\n",
            "New text: Congratulations, you won a free ticket!\n",
            "Predicted label: spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eb-ZN1KJWtUi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}